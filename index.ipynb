{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cover_page",
   "metadata": {},
   "source": [
    "# BÁO CÁO HỌC PHẦN XỬ LÝ ẢNH VÀ THỊ GIÁC MÁY TÍNH\n",
    "## NGHIÊN CỨU VÀ PHÁT TRIỂN ỨNG DỤNG PHÁT HIỆN VÀ PHÂN VÙNG LỖI SẢN PHẨM TRONG CÔNG NGHIỆP\n",
    "\n",
    "**Giảng viên hướng dẫn:** TS. Trần Thị Khánh Tiên  \n",
    "**Nhóm:** 3  \n",
    "**Ngành:** Công nghệ thông tin  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## 0. KHỞI TẠO MÔI TRƯỜNG\n",
    "Phần này chứa các mã lệnh để import thư viện và thiết lập cấu hình cơ bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning Framework\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.ops import box_iou\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "# Augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS & CONFIGURATION\n",
    "\n",
    "# Random Seed for reproducibility\n",
    "SEED = 42\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-3  # updated for SGD fine-tuning\n",
    "EPOCHS = 30\n",
    "\n",
    "# Dataset Path\n",
    "try:\n",
    "    with open(\"dataset_path.txt\", \"r\") as f:\n",
    "        DATASET_PATH = f.read().strip()\n",
    "    print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: dataset_path.txt not found. Please run download_data.py first.\")\n",
    "    DATASET_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_1",
   "metadata": {},
   "source": [
    "## CHƯƠNG 1. GIỚI THIỆU\n",
    "\n",
    "### 1.1. Bối cảnh và động lực nghiên cứu\n",
    "Trong nền sản xuất công nghiệp hiện đại, việc đảm bảo chất lượng sản phẩm là yếu tố then chốt. Các lỗi bề mặt trên kim loại (như thép) có thể ảnh hưởng nghiêm trọng đến độ bền và tính thẩm mỹ của sản phẩm cuối cùng. Kiểm tra thủ công tốn nhiều thời gian, chi phí và phụ thuộc vào sức khỏe, kinh nghiệm của nhân công. Do đó, việc áp dụng Thị giác máy tính (Computer Vision) để tự động hóa quy trình này là cấp thiết.\n",
    "\n",
    "### 1.2. Ứng dụng thực tế\n",
    "Hệ thống tự động phát hiện lỗi có thể được tích hợp vào các dây chuyền sản xuất thép, linh kiện ô tô, giúp loại bỏ sản phẩm lỗi ngay lập tức, giảm thiểu rủi ro và chi phí bảo hành.\n",
    "\n",
    "### 1.3. Mục tiêu của đề tài\n",
    "Xây dựng pipeline xử lý:\n",
    "1. **Input:** Ảnh chụp bề mặt kim loại.\n",
    "2. **Detection:** Xác định vị trí và phân loại lỗi (Bounding Box & Class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_2",
   "metadata": {},
   "source": [
    "## CHƯƠNG 2. TỔNG QUAN LÝ THUYẾT\n",
    "\n",
    "### 2.1. Tổng quan về bài toán Object Detection\n",
    "Object Detection là bài toán xác định vị trí (localization) và phân loại (classification) các đối tượng trong ảnh. Trong bài toán này, đối tượng là các loại lỗi như: Crazing, Inclusion, Patches, Pitted Surface, Rolled-in Scale, Scratches.\n",
    "\n",
    "### 2.2. Các mô hình học sâu phổ biến\n",
    "* **Two-stage Detectors:** Faster R-CNN (độ chính xác cao, nhưng tốc độ chậm hơn).\n",
    "* **One-stage Detectors:** YOLO (You Only Look Once), SSD (tốc độ nhanh, phù hợp realtime).\n",
    "\n",
    "### 2.3. Dataset NEU Surface Defect\n",
    "Bộ dữ liệu bao gồm 6 loại lỗi phổ biến trên bề mặt thép cán nóng, được thu thập bởi Đại học Northeastern (NEU).\n",
    "\n",
    "### 2.4 Lý do lựa chọn mô hình đề xuất (Faster R-CNN / YOLO)\n",
    "Lựa chọn mô hình dựa trên sự cân bằng giữa độ chính xác và tốc độ. Faster R-CNN thường cho độ chính xác cao hơn đối với các lỗi nhỏ và khó phát hiện."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_3",
   "metadata": {},
   "source": [
    "## CHƯƠNG 3. BỘ DỮ LIỆU VÀ TIỀN XỬ LÝ\n",
    "\n",
    "### 3.1. Giới thiệu bộ dữ liệu NEU Surface Defect Database\n",
    "Sử dụng bộ dữ liệu `kaustubhdikshit/neu-surface-defect-database` từ Kaggle.\n",
    "* **Số lượng ảnh:** 1800 ảnh.\n",
    "* **Classes:** 'crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches'.\n",
    "\n",
    "### 3.2. Tiền xử lý (Preprocessing)\n",
    "* **Resize:** Đưa ảnh về kích thước cố định.\n",
    "* **Normalization:** Chuẩn hóa giá trị pixel.\n",
    "* **Data Splitting:** Chia tập Train/Validation/Test.\n",
    "\n",
    "### 3.3. Các kỹ thuật tăng cường dữ liệu (Data Augmentation)\n",
    "* Flip, Rotate, Random Brightness, v.v để tăng tính đa dạng cho dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEUDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, stage='Train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "        self.classes = ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n",
    "        \n",
    "        subdir = 'train' if stage == 'Train' else 'validation'\n",
    "        # For NEU dataset on Kaggle, the structure might vary. Assuming valid path structure\n",
    "        # Kaggle Path: .../neu-surface-defect-database/NEU-DET/train/images\n",
    "        self.base_dir = os.path.join(root_dir, 'NEU-DET', subdir)\n",
    "        \n",
    "        self.img_dir = os.path.join(self.base_dir, 'images')\n",
    "        self.xml_dir = os.path.join(self.base_dir, 'annotations')\n",
    "        \n",
    "        if not os.path.exists(self.img_dir):\n",
    "             # Try falling back if path structure is different (common in kaggle datasets)\n",
    "             # Or strict error\n",
    "             pass \n",
    "        \n",
    "        self.images = []\n",
    "        if os.path.exists(self.img_dir):\n",
    "            for root, dirs, files in os.walk(self.img_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.jpg'):\n",
    "                        self.images.append(os.path.join(root, file))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img_name = os.path.basename(img_path)\n",
    "        xml_name = img_name.replace('.jpg', '.xml')\n",
    "        xml_path = os.path.join(self.xml_dir, xml_name)\n",
    "        \n",
    "        # Read Image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(xml_path):\n",
    "            try:\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "                for obj in root.findall('object'):\n",
    "                    name = obj.find('name').text\n",
    "                    if name in self.classes:\n",
    "                        label = self.classes.index(name) + 1 # 1-index for FG\n",
    "                        labels.append(label)\n",
    "                        \n",
    "                        bndbox = obj.find('bndbox')\n",
    "                        xmin = int(bndbox.find('xmin').text)\n",
    "                        ymin = int(bndbox.find('ymin').text)\n",
    "                        xmax = int(bndbox.find('xmax').text)\n",
    "                        ymax = int(bndbox.find('ymax').text)\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing XML for {xml_path}: {e}\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        boxes = np.array(boxes, dtype=np.float32)  # Convert to NumPy array for Albumentations\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        if self.transform:\n",
    "            # Note: albumentations for detection requires bbox_params\n",
    "            augmented = self.transform(image=image, bboxes=boxes, labels=labels.numpy())\n",
    "            image = augmented['image']\n",
    "            target[\"boxes\"] = torch.as_tensor(augmented['bboxes'], dtype=torch.float32)\n",
    "            \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize train_dataset and test_dataset\n",
    "train_dataset = NEUDataset(root_dir=DATASET_PATH, transform=A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])), stage='Train')\n",
    "\n",
    "test_dataset = NEUDataset(root_dir=DATASET_PATH, transform=A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])), stage='Validation')\n",
    "\n",
    "# Custom collate function to handle variable-length bounding boxes\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for img, target in batch:\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "    return images, targets\n",
    "\n",
    "# Initialize DataLoader with custom collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Visualization Function\n",
    "def visualize_batch(loader):\n",
    "    images, targets = next(iter(loader))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(4, len(images))):\n",
    "        # Un-normalize for visualization\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for box in targets[i]['boxes']:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, \n",
    "                                              fill=False, color='red', linewidth=2))\n",
    "        plt.title(\"Image with BBoxes\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run visualization\n",
    "print(\"Visualizing Train Batch...\")\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_4",
   "metadata": {},
   "source": [
    "## CHƯƠNG 4. PHƯƠNG PHÁP ĐỀ XUẤT\n",
    "\n",
    "### 4.1. Kiến trúc Faster R-CNN\n",
    "Sử dụng mô hình Faster R-CNN từ thư viện `torchvision.models.detection` để phát hiện các lỗi bề mặt sản phẩm. Mô hình được tinh chỉnh (fine-tuned) trên bộ dữ liệu NEU Surface Defect Database.\n",
    "\n",
    "### 4.2. Hàm mất mát (Loss Function)\n",
    "Hàm mất mát được sử dụng là tổng hợp của Classification Loss và Localization Loss, được tích hợp sẵn trong `torchvision`.\n",
    "\n",
    "### 4.3. Thiết lập tham số huấn luyện\n",
    "- Optimizer: SGD với Momentum.\n",
    "- Learning Rate: 0.005.\n",
    "- Epochs: 30.\n",
    "- Batch Size: 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFasterCNN = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Modify the classifier to match the number of classes in the NEU dataset\n",
    "num_classes = 7  # 6 defect classes + 1 background\n",
    "in_features = modelFasterCNN.roi_heads.box_predictor.cls_score.in_features\n",
    "modelFasterCNN.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Move the modelFasterCNN to the appropriate device\n",
    "modelFasterCNN = modelFasterCNN.to(DEVICE)\n",
    "\n",
    "# print(modelUnet)\n",
    "# print(modelFasterCNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77033f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and LR scheduler for Faster R-CNN (SGD fine-tune)\n",
    "optimizer = torch.optim.SGD(\n",
    "    modelFasterCNN.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(f\"Optimizer and scheduler initialized (LR={LEARNING_RATE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_5",
   "metadata": {},
   "source": [
    "## CHƯƠNG 5. THỰC NGHIỆM VÀ KẾT QUẢ\n",
    "\n",
    "### 5.1. Môi trường thực nghiệm và độ đo đánh giá\n",
    "- **Môi trường thực nghiệm:**\n",
    "  - GPU: NVIDIA RTX 3090.\n",
    "  - Framework: PyTorch.\n",
    "  - Bộ dữ liệu: NEU Surface Defect Database.\n",
    "\n",
    "- **Độ đo đánh giá:**\n",
    "  - Mean Average Precision (mAP).\n",
    "  - Precision và Recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3571081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model (best_model.pth)\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelFasterCNN.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = [img.to(DEVICE) for img in images]\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = modelFasterCNN(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += losses.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}] | Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "torch.save(modelFasterCNN.state_dict(), \"best_model.pth\")\n",
    "print(\"Saved best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = modelFasterCNN\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=DEVICE))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e37a15",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2. Kết quả định lượng (Quantitative Results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b391567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5.1 Metric đánh giá\n",
    "# =========================\n",
    "metric = MeanAveragePrecision(\n",
    "    iou_type=\"bbox\",\n",
    "    iou_thresholds=[0.5]  \n",
    ")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "        images = [img.to(DEVICE) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        preds = []\n",
    "        gts = []\n",
    "\n",
    "        for out, tgt in zip(outputs, targets):\n",
    "            # Prediction\n",
    "            preds.append({\n",
    "                \"boxes\": out[\"boxes\"].cpu(),\n",
    "                \"scores\": out[\"scores\"].cpu(),\n",
    "                \"labels\": out[\"labels\"].cpu()\n",
    "            })\n",
    "\n",
    "            # Ground Truth\n",
    "            gts.append({\n",
    "                \"boxes\": tgt[\"boxes\"].cpu(),\n",
    "                \"labels\": tgt[\"labels\"].cpu()\n",
    "            })\n",
    "\n",
    "        # cập nhật metric\n",
    "        metric.update(preds, gts)\n",
    "\n",
    "# =========================\n",
    "# 5.2 Kết quả định lượng\n",
    "# =========================\n",
    "results = metric.compute()\n",
    "\n",
    "print(f\"mAP@0.5: {results['map'].item():.4f}\")\n",
    "print(f\"Precision: {results['map_50'].item():.4f}\")\n",
    "print(f\"Recall: {results['mar_100'].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b71a21",
   "metadata": {},
   "source": [
    "\n",
    "### 5.3. Kết quả định tính và trực quan hóa (Qualitative Results)\n",
    "Hiển thị một số hình ảnh dự đoán từ tập kiểm tra với Bounding Boxes và nhãn dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vẽ prediction\n",
    "\n",
    "img = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "img = (img * 255).astype(\"uint8\")\n",
    "\n",
    "boxes = outputs[0][\"boxes\"]\n",
    "scores = outputs[0][\"scores\"]\n",
    "\n",
    "for box, score in zip(boxes, scores):\n",
    "    if score < CONF_THRESHOLD:\n",
    "        continue\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        f\"{score:.2f}\",\n",
    "        (x1, y1 - 5),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 255, 0),\n",
    "        1\n",
    "    )\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_5_2",
   "metadata": {},
   "source": [
    "### 5.2. Kết quả định tính (Visual Results)\n",
    "Hiển thị kết quả dự đoán trên tập test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_6",
   "metadata": {},
   "source": [
    "## CHƯƠNG 6. PHÂN TÍCH VÀ THẢO LUẬN\n",
    "\n",
    "* **Ưu điểm:**\n",
    "  - Mô hình Faster R-CNN đạt độ chính xác cao trên các loại lỗi bề mặt sản phẩm.\n",
    "  - Khả năng phát hiện tốt ngay cả với các lỗi nhỏ và khó nhận biết.\n",
    "\n",
    "* **Hạn chế:**\n",
    "  - Tốc độ dự đoán chậm hơn so với các mô hình một giai đoạn (One-stage Detectors) như YOLO.\n",
    "  - Hiệu suất giảm trên các ảnh có độ tương phản thấp.\n",
    "\n",
    "* **Phân tích lỗi:**\n",
    "  - Một số trường hợp dự đoán sai xảy ra khi các lỗi bị che khuất hoặc không rõ ràng.\n",
    "  - Cần cải thiện khả năng phát hiện trong các điều kiện ánh sáng yếu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
