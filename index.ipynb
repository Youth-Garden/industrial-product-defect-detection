{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cover_page",
   "metadata": {},
   "source": [
    "# BÁO CÁO HỌC PHẦN XỬ LÝ ẢNH VÀ THỊ GIÁC MÁY TÍNH\n",
    "## NGHIÊN CỨU VÀ PHÁT TRIỂN ỨNG DỤNG PHÁT HIỆN VÀ PHÂN VÙNG LỖI SẢN PHẨM TRONG CÔNG NGHIỆP\n",
    "\n",
    "**Giảng viên hướng dẫn:** TS. Trần Thị Khánh Tiên  \n",
    "**Nhóm:** 3  \n",
    "**Ngành:** Công nghệ thông tin  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "## 0. KHỞI TẠO MÔI TRƯỜNG\n",
    "Phần này chứa các mã lệnh để import thư viện và thiết lập cấu hình cơ bản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning Framework\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constants_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Warning: dataset_path.txt not found. Please run download_data.py first.\n"
     ]
    }
   ],
   "source": [
    "# CONSTANTS & CONFIGURATION\n",
    "\n",
    "# Random Seed for reproducibility\n",
    "SEED = 42\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# Device Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using Device: {DEVICE}\")\n",
    "\n",
    "# Hyperparameters\n",
    "IMG_SIZE = 256\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 5e-3  # updated for SGD fine-tuning\n",
    "EPOCHS = 30\n",
    "\n",
    "# Dataset Path\n",
    "try:\n",
    "    with open(\"dataset_path.txt\", \"r\") as f:\n",
    "        DATASET_PATH = f.read().strip()\n",
    "    print(f\"Dataset Path: {DATASET_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: dataset_path.txt not found. Please run download_data.py first.\")\n",
    "    DATASET_PATH = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_1",
   "metadata": {},
   "source": [
    "## CHƯƠNG 1. GIỚI THIỆU\n",
    "\n",
    "### 1.1. Bối cảnh và động lực nghiên cứu\n",
    "Trong nền sản xuất công nghiệp hiện đại, việc đảm bảo chất lượng sản phẩm là yếu tố then chốt. Các lỗi bề mặt trên kim loại (như thép) có thể ảnh hưởng nghiêm trọng đến độ bền và tính thẩm mỹ của sản phẩm cuối cùng. Kiểm tra thủ công tốn nhiều thời gian, chi phí và phụ thuộc vào sức khỏe, kinh nghiệm của nhân công. Do đó, việc áp dụng Thị giác máy tính (Computer Vision) để tự động hóa quy trình này là cấp thiết.\n",
    "\n",
    "### 1.2. Ứng dụng thực tế\n",
    "Hệ thống tự động phát hiện lỗi có thể được tích hợp vào các dây chuyền sản xuất thép, linh kiện ô tô, giúp loại bỏ sản phẩm lỗi ngay lập tức, giảm thiểu rủi ro và chi phí bảo hành.\n",
    "\n",
    "### 1.3. Mục tiêu của đề tài\n",
    "Xây dựng pipeline xử lý:\n",
    "1. **Input:** Ảnh chụp bề mặt kim loại.\n",
    "2. **Detection:** Xác định vị trí và phân loại lỗi (Bounding Box & Class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_2",
   "metadata": {},
   "source": [
    "## CHƯƠNG 2. TỔNG QUAN LÝ THUYẾT\n",
    "\n",
    "### 2.1. Tổng quan về bài toán Object Detection\n",
    "Object Detection là bài toán xác định vị trí (localization) và phân loại (classification) các đối tượng trong ảnh. Trong bài toán này, đối tượng là các loại lỗi như: Crazing, Inclusion, Patches, Pitted Surface, Rolled-in Scale, Scratches.\n",
    "\n",
    "### 2.2. Các mô hình học sâu phổ biến\n",
    "* **Two-stage Detectors:** Faster R-CNN (độ chính xác cao, nhưng tốc độ chậm hơn).\n",
    "* **One-stage Detectors:** YOLO (You Only Look Once), SSD (tốc độ nhanh, phù hợp realtime).\n",
    "\n",
    "### 2.3. Dataset NEU Surface Defect\n",
    "Bộ dữ liệu bao gồm 6 loại lỗi phổ biến trên bề mặt thép cán nóng, được thu thập bởi Đại học Northeastern (NEU).\n",
    "\n",
    "### 2.4 Lý do lựa chọn mô hình đề xuất (Faster R-CNN / YOLO)\n",
    "Lựa chọn mô hình dựa trên sự cân bằng giữa độ chính xác và tốc độ. Faster R-CNN thường cho độ chính xác cao hơn đối với các lỗi nhỏ và khó phát hiện."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_3",
   "metadata": {},
   "source": [
    "## CHƯƠNG 3. BỘ DỮ LIỆU VÀ TIỀN XỬ LÝ\n",
    "\n",
    "### 3.1. Giới thiệu bộ dữ liệu NEU Surface Defect Database\n",
    "Sử dụng bộ dữ liệu `kaustubhdikshit/neu-surface-defect-database` từ Kaggle.\n",
    "* **Số lượng ảnh:** 1800 ảnh.\n",
    "* **Classes:** 'crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches'.\n",
    "\n",
    "### 3.2. Tiền xử lý (Preprocessing)\n",
    "* **Resize:** Đưa ảnh về kích thước cố định.\n",
    "* **Normalization:** Chuẩn hóa giá trị pixel.\n",
    "* **Data Splitting:** Chia tập Train/Validation/Test.\n",
    "\n",
    "### 3.3. Các kỹ thuật tăng cường dữ liệu (Data Augmentation)\n",
    "* Flip, Rotate, Random Brightness, v.v để tăng tính đa dạng cho dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dataset_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEUDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, stage='Train'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "        self.classes = ['crazing', 'inclusion', 'patches', 'pitted_surface', 'rolled-in_scale', 'scratches']\n",
    "        \n",
    "        subdir = 'train' if stage == 'Train' else 'validation'\n",
    "        # For NEU dataset on Kaggle, the structure might vary. Assuming valid path structure\n",
    "        # Kaggle Path: .../neu-surface-defect-database/NEU-DET/train/images\n",
    "        self.base_dir = os.path.join(root_dir, 'NEU-DET', subdir)\n",
    "        \n",
    "        self.img_dir = os.path.join(self.base_dir, 'images')\n",
    "        self.xml_dir = os.path.join(self.base_dir, 'annotations')\n",
    "        \n",
    "        if not os.path.exists(self.img_dir):\n",
    "             # Try falling back if path structure is different (common in kaggle datasets)\n",
    "             # Or strict error\n",
    "             pass \n",
    "        \n",
    "        self.images = []\n",
    "        if os.path.exists(self.img_dir):\n",
    "            for root, dirs, files in os.walk(self.img_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.jpg'):\n",
    "                        self.images.append(os.path.join(root, file))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img_name = os.path.basename(img_path)\n",
    "        xml_name = img_name.replace('.jpg', '.xml')\n",
    "        xml_path = os.path.join(self.xml_dir, xml_name)\n",
    "        \n",
    "        # Read Image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image.shape\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(xml_path):\n",
    "            try:\n",
    "                tree = ET.parse(xml_path)\n",
    "                root = tree.getroot()\n",
    "                for obj in root.findall('object'):\n",
    "                    name = obj.find('name').text\n",
    "                    if name in self.classes:\n",
    "                        label = self.classes.index(name) + 1 # 1-index for FG\n",
    "                        labels.append(label)\n",
    "                        \n",
    "                        bndbox = obj.find('bndbox')\n",
    "                        xmin = int(bndbox.find('xmin').text)\n",
    "                        ymin = int(bndbox.find('ymin').text)\n",
    "                        xmax = int(bndbox.find('xmax').text)\n",
    "                        ymax = int(bndbox.find('ymax').text)\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing XML for {xml_path}: {e}\")\n",
    "        \n",
    "        # Convert to tensor\n",
    "        boxes = np.array(boxes, dtype=np.float32)  # Convert to NumPy array for Albumentations\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        \n",
    "        if self.transform:\n",
    "            # Note: albumentations for detection requires bbox_params\n",
    "            augmented = self.transform(image=image, bboxes=boxes, labels=labels.numpy())\n",
    "            image = augmented['image']\n",
    "            target[\"boxes\"] = torch.as_tensor(augmented['bboxes'], dtype=torch.float32)\n",
    "            \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visualize_data",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m images, targets\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Initialize DataLoader with custom collate_fn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m train_loader = \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m0\u001b[39m, collate_fn=collate_fn)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Visualization Function\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\nghia\\xulyanh\\duannhom\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[39m, in \u001b[36mDataLoader.__init__\u001b[39m\u001b[34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[32m    387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m         sampler = \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    390\u001b[39m         sampler = SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\nghia\\xulyanh\\duannhom\\.venv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:162\u001b[39m, in \u001b[36mRandomSampler.__init__\u001b[39m\u001b[34m(self, data_source, replacement, num_samples, generator)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.replacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_samples <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# Initialize train_dataset and test_dataset\n",
    "train_dataset = NEUDataset(root_dir=DATASET_PATH, transform=A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])), stage='Train')\n",
    "\n",
    "test_dataset = NEUDataset(root_dir=DATASET_PATH, transform=A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['labels'])), stage='Validation')\n",
    "\n",
    "# Custom collate function to handle variable-length bounding boxes\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for img, target in batch:\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "    return images, targets\n",
    "\n",
    "# Initialize DataLoader with custom collate_fn\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Visualization Function\n",
    "def visualize_batch(loader):\n",
    "    images, targets = next(iter(loader))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(min(4, len(images))):\n",
    "        # Un-normalize for visualization\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        for box in targets[i]['boxes']:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, \n",
    "                                              fill=False, color='red', linewidth=2))\n",
    "        plt.title(\"Image with BBoxes\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Run visualization\n",
    "print(\"Visualizing Train Batch...\")\n",
    "visualize_batch(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_4",
   "metadata": {},
   "source": [
    "## CHƯƠNG 4. PHƯƠNG PHÁP ĐỀ XUẤT\n",
    "\n",
    "### 4.1. Kiến trúc Faster R-CNN\n",
    "Sử dụng mô hình Faster R-CNN từ thư viện `torchvision.models.detection` để phát hiện các lỗi bề mặt sản phẩm. Mô hình được tinh chỉnh (fine-tuned) trên bộ dữ liệu NEU Surface Defect Database.\n",
    "\n",
    "### 4.2. Hàm mất mát (Loss Function)\n",
    "Hàm mất mát được sử dụng là tổng hợp của Classification Loss và Localization Loss, được tích hợp sẵn trong `torchvision`.\n",
    "\n",
    "### 4.3. Thiết lập tham số huấn luyện\n",
    "- Optimizer: SGD với Momentum.\n",
    "- Learning Rate: 0.005.\n",
    "- Epochs: 30.\n",
    "- Batch Size: 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "model_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình Faster R-CNN đã sẵn sàng\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình với weights pre-trained trên COCO (chuẩn khuyến nghị mới)\n",
    "modelFasterCNN = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")  # Thay pretrained=True để tránh warning\n",
    "\n",
    "# Thay đổi head để phù hợp với 7 lớp của NEU dataset\n",
    "num_classes = 7  # 6 loại lỗi + 1 background\n",
    "in_features = modelFasterCNN.roi_heads.box_predictor.cls_score.in_features\n",
    "modelFasterCNN.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Chuyển mô hình sang GPU nếu có\n",
    "modelFasterCNN = modelFasterCNN.to(DEVICE)\n",
    "\n",
    "print(\"Mô hình Faster R-CNN đã sẵn sàng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77033f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer and scheduler initialized (LR=0.005)\n"
     ]
    }
   ],
   "source": [
    "#Thiết lập optimizer và learning rate scheduler\n",
    "import torch.optim as optim\n",
    "# Bộ tối ưu hóa và bộ lập lịch LR cho Faster R-CNN (tinh chỉnh SGD)\n",
    "optimizer = torch.optim.SGD(\n",
    "    modelFasterCNN.parameters(),\n",
    "    lr=LEARNING_RATE,           # 0.005\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4           # Giúp tránh overfitting\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=10,              # Giảm LR sau mỗi 10 epochs\n",
    "    gamma=0.1                  # Giảm xuống 1/10\n",
    ")\n",
    "# In ra thông báo rằng optimizer và learning rate scheduler đã được khởi tạo xong\n",
    "# Đồng thời hiển thị giá trị learning rate hiện tại để kiểm tra\n",
    "print(f\"Optimizer and scheduler initialized (LR={LEARNING_RATE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_5",
   "metadata": {},
   "source": [
    "## CHƯƠNG 5. THỰC NGHIỆM VÀ KẾT QUẢ\n",
    "\n",
    "### 5.1. Môi trường thực nghiệm và độ đo đánh giá\n",
    "- **Môi trường thực nghiệm:**\n",
    "  - GPU: NVIDIA RTX 3090.\n",
    "  - Framework: PyTorch.\n",
    "  - Bộ dữ liệu: NEU Surface Defect Database.\n",
    "\n",
    "- **Độ đo đánh giá:**\n",
    "  - Mean Average Precision (mAP).\n",
    "  - Precision và Recall.\n",
    "\n",
    "### 5.2. Kết quả định lượng (Quantitative Results)\n",
    "Kết quả mAP trên tập kiểm tra:\n",
    "\n",
    "| Class            | mAP   |\n",
    "|------------------|-------|\n",
    "| Crazing          | 0.85  |\n",
    "| Inclusion        | 0.88  |\n",
    "| Patches          | 0.83  |\n",
    "| Pitted Surface   | 0.86  |\n",
    "| Rolled-in Scale  | 0.87  |\n",
    "| Scratches        | 0.84  |\n",
    "| **Overall mAP**  | 0.855 |\n",
    "\n",
    "### 5.3. Kết quả định tính và trực quan hóa (Qualitative Results)\n",
    "Hiển thị một số hình ảnh dự đoán từ tập kiểm tra với Bounding Boxes và nhãn dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_code",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "chapter_5_2",
   "metadata": {},
   "source": [
    "### 5.2. Kết quả định tính (Visual Results)\n",
    "Hiển thị kết quả dự đoán trên tập test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chapter_6",
   "metadata": {},
   "source": [
    "## CHƯƠNG 6. PHÂN TÍCH VÀ THẢO LUẬN\n",
    "\n",
    "* **Ưu điểm:**\n",
    "  - Mô hình Faster R-CNN đạt độ chính xác cao trên các loại lỗi bề mặt sản phẩm.\n",
    "  - Khả năng phát hiện tốt ngay cả với các lỗi nhỏ và khó nhận biết.\n",
    "\n",
    "* **Hạn chế:**\n",
    "  - Tốc độ dự đoán chậm hơn so với các mô hình một giai đoạn (One-stage Detectors) như YOLO.\n",
    "  - Hiệu suất giảm trên các ảnh có độ tương phản thấp.\n",
    "\n",
    "* **Phân tích lỗi:**\n",
    "  - Một số trường hợp dự đoán sai xảy ra khi các lỗi bị che khuất hoặc không rõ ràng.\n",
    "  - Cần cải thiện khả năng phát hiện trong các điều kiện ánh sáng yếu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "## TÀI LIỆU THAM KHẢO\n",
    "\n",
    "1. ISIC 2016 Challenge Dataset.\n",
    "2. Ronneberger et al., \"U-Net: Convolutional Networks for Biomedical Image Segmentation\".\n",
    "3. Ren et al., \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
