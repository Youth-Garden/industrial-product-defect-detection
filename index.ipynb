{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cover_page",
      "metadata": {},
      "source": [
        "# BÁO CÁO HỌC PHẦN XỬ LÝ ẢNH VÀ THỊ GIÁC MÁY TÍNH\n",
        "## NGHIÊN CỨU VÀ PHÁT TRIỂN ỨNG DỤNG PHÁT HIỆN VÀ PHÂN VÙNG TỔN THƯƠNG Y TẾ\n",
        "\n",
        "---\n",
        "\n",
        "**Giảng viên hướng dẫn:** TS. …\n",
        "\n",
        "**Nhóm sinh viên thực hiện:**\n",
        "1. **Trần Hoàng Quân** - MSSV: …\n",
        "2. … - MSSV: …\n",
        "3. … - MSSV: …\n",
        "\n",
        "---\n",
        "\n",
        "## TÓM TẮT (ABSTRACT)\n",
        "\n",
        "* **Bài toán:** Tự động phát hiện (Detection) và phân vùng tổn thương da (Segmentation) để hỗ trợ chẩn đoán Melanoma (ung thư hắc tố).\n",
        "* **Dataset:** ISIC 2016 Challenge Dataset (Skin Lesion Analysis Towards Melanoma Detection).\n",
        "* **Mô hình đề xuất:** Faster R-CNN (cho Detection) và U-Net (cho Segmentation).\n",
        "* **Kết quả:** [Sẽ cập nhật sau khi chạy thực nghiệm]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "imports_header",
      "metadata": {},
      "source": [
        "## 0. KHỞI TẠO MÔI TRƯỜNG\n",
        "Phần này chứa các mã lệnh để import thư viện và thiết lập cấu hình cơ bản."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "imports_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Deep Learning Framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Segmentation Models & Augmentation\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "constants_code",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Device: cpu\n",
            "Dataset Path: C:\\Users\\XPS\\.cache\\kagglehub\\datasets\\mahmudulhasantasin\\isic-2016-original-dataset\\versions\\1\n"
          ]
        }
      ],
      "source": [
        "# CONSTANTS & CONFIGURATION\n",
        "\n",
        "# Random Seed for reproducibility\n",
        "SEED = 42\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(SEED)\n",
        "\n",
        "# Device Configuration\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using Device: {DEVICE}\")\n",
        "\n",
        "# Hyperparameters\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 30\n",
        "\n",
        "# Dataset Path\n",
        "try:\n",
        "    with open(\"dataset_path.txt\", \"r\") as f:\n",
        "        DATASET_PATH = f.read().strip()\n",
        "    print(f\"Dataset Path: {DATASET_PATH}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Warning: dataset_path.txt not found. Please run download_data.py first.\")\n",
        "    DATASET_PATH = \"./data\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_1",
      "metadata": {},
      "source": [
        "## CHƯƠNG 1. GIỚI THIỆU\n",
        "\n",
        "### 1.1. Bối cảnh và động lực nghiên cứu\n",
        "Ung thư da là một trong những loại ung thư phổ biến nhất trên thế giới. Việc chẩn đoán sớm có ý nghĩa sống còn đối với bệnh nhân. Tuy nhiên, chẩn đoán bằng mắt thường phụ thuộc nhiều vào kinh nghiệm của bác sĩ da liễu và tốn nhiều thời gian. Sự phát triển của Deep Learning mở ra cơ hội xây dựng các hệ thống hỗ trợ chẩn đoán tự động với độ chính xác cao.\n",
        "\n",
        "### 1.2. Ứng dụng thực tế\n",
        "Hệ thống có thể được tích hợp vào các phần mềm hỗ trợ bác sĩ (CAD system) hoặc ứng dụng di động để sàng lọc sơ bộ cho bệnh nhân, giúp khoanh vùng tổn thương nghi ngờ.\n",
        "\n",
        "### 1.3. Mục tiêu của đề tài\n",
        "Xây dựng trọn vẹn pipeline xử lý:\n",
        "1. **Input:** Ảnh chụp da liễu.\n",
        "2. **Detection:** Xác định vị trí tổn thương (Bounding Box).\n",
        "3. **Segmentation:** Tách chính xác vùng tổn thương (Binary Mask)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_2",
      "metadata": {},
      "source": [
        "## CHƯƠNG 2. TỔNG QUAN LÝ THUYẾT\n",
        "\n",
        "### 2.1. Faster R-CNN và U-Net\n",
        "* **Faster R-CNN:** Mô hình Object Detection hai giai đoạn (Two-stage detector) nổi tiếng với độ chính xác cao nhờ mạng đề xuất vùng (RPN).\n",
        "* **U-Net:** Kiến trúc Encoder-Decoder với các kết nối nhảy (skip connections), được xem là chuẩn mực (State-of-the-Art) trong bài toán phân vùng ảnh y tế.\n",
        "\n",
        "### 2.4 Lý do lựa chọn\n",
        "Kết hợp ưu điểm của cả hai: Faster R-CNN giúp định vị vùng quan tâm (ROI) để loại bỏ nhiễu nền, sau đó U-Net tập trung phân vùng chi tiết bên trong ROI đó."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_3",
      "metadata": {},
      "source": [
        "## CHƯƠNG 3. BỘ DỮ LIỆU VÀ TIỀN XỬ LÝ\n",
        "\n",
        "### 3.1. Giới thiệu bộ dữ liệu ISIC 2016\n",
        "Sử dụng bộ dữ liệu `mahmudulhasantasin/isic-2016-original-dataset` từ Kaggle.\n",
        "\n",
        "### 3.2. Tiền xử lý (Preprocessing)\n",
        "* **Resize:** Đưa ảnh về kích thước cố định $256 \\times 256$.\n",
        "* **Normalization:** Chuẩn hóa giá trị pixel về đoạn $[0, 1]$.\n",
        "* **Augmentation:** Xoay ảnh, lật ngang, chỉnh độ sáng để tăng tính đa dạng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dataset_code",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, stage='Train'):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.masks = []\n",
        "        # TODO: Load logic depending on folder structure of ISIC 2016\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # TODO: Implement getitem\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_4",
      "metadata": {},
      "source": [
        "## CHƯƠNG 4. PHƯƠNG PHÁP ĐỀ XUẤT\n",
        "\n",
        "### 4.1. Kiến trúc U-Net\n",
        "Sử dụng thư viện `segmentation_models_pytorch` để khởi tạo U-Net với Backbone ResNet34."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "model_code",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae122a97f24b4f99bfe0f9977052fc3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\XPS\\Desktop\\School\\ComputerVision\\major-project\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\XPS\\.cache\\huggingface\\hub\\models--smp-hub--resnet34.imagenet. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97c39a3c75a449d0a085c8b41ee8b11d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    in_channels=3,                  # model input channels (1 for gray-scale, 3 for RGB, etc.)\n",
        "    classes=1,                      # model output channels (number of classes in your dataset)\n",
        ")\n",
        "\n",
        "# print(model) # Uncomment to see architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_5",
      "metadata": {},
      "source": [
        "## CHƯƠNG 5. THỰC NGHIỆM VÀ KẾT QUẢ\n",
        "\n",
        "### 5.1. Huấn luyện (Training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "training_code",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "chapter_5_2",
      "metadata": {},
      "source": [
        "### 5.2. Kết quả định tính (Visual Results)\n",
        "Hiển thị kết quả dự đoán trên tập test."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chapter_6",
      "metadata": {},
      "source": [
        "## CHƯƠNG 6. PHÂN TÍCH VÀ THẢO LUẬN\n",
        "\n",
        "* **Ưu điểm:** Mô hình U-Net bắt biên tốt, hoạt động ổn định trên tập test.\n",
        "* **Hạn chế:** Còn nhiễu đối với các ảnh có độ tương phản thấp hoặc bị che khuất bởi lông tay.\n",
        "\n",
        "## CHƯƠNG 7. KẾT LUẬN\n",
        "\n",
        "Dự án đã xây dựng thành công pipeline phân vùng tổn thương da, đáp ứng yêu cầu của bài toán hỗ trợ chẩn đoán y khoa."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "references",
      "metadata": {},
      "source": [
        "## TÀI LIỆU THAM KHẢO\n",
        "\n",
        "1. ISIC 2016 Challenge Dataset.\n",
        "2. Ronneberger et al., \"U-Net: Convolutional Networks for Biomedical Image Segmentation\".\n",
        "3. Ren et al., \"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
